---
title: "p8105_hw5_cgd2137"
author: "Carolina Downie"
date: "11/1/2017"
output: html_document
---

```{r loading packages}

library(ggplot2)
library(tidyverse)
library(rvest)
library(httr)
library(stringr)
library(janitor)
library(haven)
library(stringr)
library(forcats)
library(tidytext)
library(viridis)

knitr::opts_chunk$set(
  fig.width = 11,
  fig.asp = .6,
  out.width = "90%")
```

#Problem 1--Subway entrances in NYC subways: 

```{r loading and cleaning New York subway data}
nyc_subway <- GET("https://data.ny.gov/resource/hvwh-qtfg.json", query = list("$limit" = 2000)) %>% 
  content("text") %>%
  jsonlite::fromJSON() %>%
  select(station_name, north_south_street, east_west_street, entrance_latitude, entrance_longitude, corner)
```

Making a plot showing the number of entrances for each subway station (restricted to stations that have more than 10 entrances). 

```{r number of entrances for each subway station}

nyc_subway %>% group_by(station_name) %>%
  mutate(num_entrances = n()) %>%
  filter(num_entrances > 10) %>%
  select(station_name, num_entrances) %>%
  unique(.) %>%
  ggplot(aes(x = forcats::fct_reorder(station_name, num_entrances), y = num_entrances, group = station_name)) + 
    geom_bar(stat = "identity") + labs(
    title = "Number of entrances for each subway station",
    x = "Subway station",
    y = "Number of entrances") +
    theme(axis.text.x = element_text(angle = 90, hjust = 1)) 
```


Calculating the number of stations with names containing "St" and ending in "St": 

```{r subway stations containing St}

nyc_subway_contains_st<-nyc_subway %>% filter(str_detect(station_name, "St")) 

```

There are `r length(unique(nyc_subway_contains_st$station_name))` subway stations containing "St" in their name. 

```{r subway statins ending in St}
nyc_subway_ends_St<-nyc_subway_contains_st %>% 
  pull(station_name) %>% 
  str_locate(., "St") %>% 
  data.frame() %>% 
  cbind(., nyc_subway_contains_st) %>%
  filter(end == str_length(station_name))

```

There are `r length(unique(nyc_subway_ends_St$station_name))` subway stations with names ending in "St". 

#Problem 2--Game of Thrones viewers:

```{r loading GoT wikipedia chart}
url<- "https://en.wikipedia.org/wiki/Game_of_Thrones#cite_note-S3ratings-277"

ratings_xml <- (read_html(url) %>% html_nodes(css = "table"))[[4]] %>% html_table(header = TRUE) %>% data.frame()

```

Tidying dataset to include variables for season, episode, viewers, and a unique episode ID of the form SX_EYY where X and Y are season or episode numbers.

```{r tidying GoT chart}

GoT_ratings <- ratings_xml %>% select(-c(Average, Season)) %>% 
  rename(season = Season.1) %>%
  gather(key = episode, value = num_viewers, Ep..1: Ep..10) %>%
  separate(episode, c("remove", "episode"), "\\..") %>% 
  select(-remove) %>%
  filter(num_viewers != "N/A") %>%
  mutate(episode_id = paste("S",substr(season, 1,1), "_","E",substr(episode, 1, 2)), num_viewers = as.numeric(num_viewers)) 

```



Making a plot that shows the number of viewers for each episode of each season.

```{r number of viewers for each episode of each season}
GoT_ratings %>% 
  mutate(episode_id = fct_reorder(episode_id, num_viewers)) %>%
  ggplot(aes(x = episode_id, y = num_viewers)) +
  geom_bar(stat = "identity") +
  labs(
    title = "Number of viewers for each Game of Thrones episode",
    x = "Episode_id",
    y = "Number of viewers (millions)") + 
  theme(legend.position = "bottom") + theme(axis.text.x = element_text(angle = 90, hjust = 1))


```


Making a boxplot of the number of viewers for each episode (across all 7 seasons).
```{r boxplot of number of viewers}
GoT_ratings %>%
  mutate(episode = fct_reorder(episode, num_viewers)) %>%
  ggplot(aes(x = episode, y = num_viewers)) +
  geom_boxplot() +
  labs(
    title = "Distribution of number of viewers for each Game of Thrones episode across seasons",
    x = "Episode",
    y = "Number of viewers (millions)") + 
  theme(legend.position = "bottom") + theme(axis.text.x = element_text(angle = 90, hjust = 1))



```


Fitting a linear model that treats number of viewers in each episode as a response and season as a categorical predictor (season 4 is reference)

```{r linear model}
GoT_ratings %>% 
  mutate(season = as.factor(season), season = fct_relevel(season, "4")) %>%
  lm(num_viewers ~ season, data = .) %>%
  broom::tidy() %>% 
  select(-std.error, -statistic) %>% 
  knitr::kable(digits = 3)
```


This linear model suggests that for seasons 1, 2, and 3, season had a negative relationship with number of viewers, whereas for seasons 5, 6, and 7, season had a positive relationship with number of viewers (when season 4 was used as the reference group). Season 7 has the largest estimated beta value. 


#Problem 3--sentiment analysis of Napolean Dynamite reviews: 

```{r loading Amazon Napolean Dynamite reviews}

dynamite_reviews <- read_csv("dynamite_reviews.csv")
```

The dataset created by this procedure contains 3 variables: title, stars, and text. Title stores the initial text that accompanies the star rating, stars stores information about how many stars the reviewer gave, and text stores the additional comments found below the star rating on the Amazon website. However, the titles are non-unique; for example, multiple reviewers titled their reviews "Five Stars". This will likely cause issues when we try to analyze the dataset, so another variable with the unique review number should be added:

```{r}
dynamite_reviews <- dynamite_reviews %>% mutate(review_num = c(1:nrow(dynamite_reviews))) %>% select(review_num, title, stars, text)

```


Creating a tidy text dataset from the above using the text in the reviews, removing stop words and using words as the token. 

```{r creating tidy text dataset}
ratings_tidy_text<- dynamite_reviews %>% unnest_tokens(word, text)

data(stop_words)

ratings_tidy_text <- anti_join(ratings_tidy_text, stop_words)

```


What words are most frequently used in five-star reviews? In 1-star reviews?
```{r most common words used in 5-star vs 1-star reviews}

words_5_stars<-ratings_tidy_text %>% 
  filter(stars == "5") %>% 
  pull(word) %>% 
  table() %>% 
  data.frame() %>% 
  arrange(desc(Freq)) %>% 
  rename(words = ".") %>% 
  top_n(., 5)

words_1_star<-ratings_tidy_text %>% 
  filter(stars == "1") %>% 
  pull(word) %>% 
  table() %>% 
  data.frame() %>% 
  arrange(desc(Freq)) %>% 
  rename(words = ".") %>% 
  top_n(., 5)



```

The top 5 most common words used in five-star reviews are `r words_5_stars$words`. The top 5 most common words used in one-star reviews are `r words_1_star$words` (Note: there may be more than 5 words for each of these if there is a tie in the frequency of most common words). 


Making a plot that shows the (approximate) log odds ratio for word appearance comparing 1-star reviews to 5-star reviews, including the 10 words with the most extreme log ORs in both directions.

```{r plotting word frequency in 5-star vs 1-star reviews}
#Calculating log odds ratio
ratings_word_ratios <- ratings_tidy_text %>% 
  mutate(stars = as.character(stars)) %>%
  filter(stars %in% c("1", "5")) %>% 
  count(word, stars) %>%
  group_by(word) %>% 
  filter(sum(n) >= 5) %>%
  ungroup() %>%
  spread(stars, n, fill = 0) %>%
  rename(One = "1", Five = "5") %>%
  mutate(
   One_odds = (One + 1) / (sum(One) + 1),
    Five_odds = (Five + 1) / (sum(Five) + 1),
    log_OR = log(One_odds / Five_odds)
  ) %>%
  arrange(desc(log_OR)) 

#Plotting the 10 words with the most extreme log odds 
ratings_word_ratios %>%
  mutate(pos_log_OR = ifelse(log_OR > 0, "One > Five", "Five > One")) %>% 
  group_by(pos_log_OR) %>%
  top_n(10, abs(log_OR)) %>%
  ungroup() %>%
  mutate(word = fct_reorder(word, log_OR)) %>%
  ggplot(aes(word, log_OR, fill = pos_log_OR)) +
  geom_col() +
  coord_flip() +
  ylab("log odds ratio (One/Five)") +
  scale_fill_discrete(name = "") +
  labs(
    title = "Plot of 10 words with most extreme log odds comparing 1-star to 5-star reviews"
  )

```


Conducting a sentiment analysis of ratings by star ratings
```{r sentiment analysis}
bing_sentiments <- get_sentiments("bing")

#Need to add review number because not all titles are unique. 
ratings_sentiments <- ratings_tidy_text %>% 
  inner_join(., bing_sentiments) %>% 
  count(review_num, sentiment) %>% 
  spread(sentiment, n, fill = 0) %>% 
  mutate(sentiment = positive - negative) %>% 
  select(review_num, sentiment)

ratings_sentiments <- right_join(dynamite_reviews, ratings_sentiments, by = "review_num")

ratings_sentiments %>% 
  mutate(review_num = factor(review_num),
    review_num = fct_reorder(review_num, sentiment), 
    stars = as.factor(stars)) %>% 
  ggplot(aes(x = review_num, 
             y = sentiment, fill = stars, color = stars)) + 
  geom_bar(stat = "identity") + 
  theme(axis.title.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  scale_fill_viridis(discrete = TRUE) + 
  scale_color_viridis(discrete = TRUE) +
  labs(
    title = "Sentiment analysis of the review texts, by number of stars"
  )

```

```{r most positive and negative reviews}
most_positive_review <- ratings_sentiments %>% filter(sentiment == max(sentiment))

most_neg_review <- ratings_sentiments %>% filter(sentiment == min(sentiment))

```

The most positive review(s) was review number `r most_positive_review$review_num`, with a sentiment score of `r most_positive_review$sentiment`. 

The most negative review(s) was review number `r most_neg_review$review_num`, with a sentiment score of `r most_neg_review$sentiment`. 
