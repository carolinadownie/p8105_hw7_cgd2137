---
title: "p8105_hw7_cgd2137"
author: "Carolina Downie"
date: "11/18/2017"
output: html_document
---

##Problem 1


```{r loading iris dataset}
library(ggplot2)
library(tidyverse)

set.seed(10)

iris_with_missing = iris %>% 
  map_df(~replace(.x, sample(1:150, 20), NA)) %>%
  mutate(Species = as.character(Species))
```

```{r Problem 1 function}

replace_missing<- function(df) {
  mean_value <- df %>% mean(na.rm = TRUE) %>% round(., 1)
  virginica<-c("virginica")
  
  if (is.character(df)) {
    df %>% replace(., is.na(df), virginica)
  } else if (is.numeric(df)) {
    df %>% replace(., is.na(df), mean_value)
  }
}

```

If I wanted to apply this function to one particular column in the dataset, I would specify column in the function input, e.g.:

```{r}
replace_missing(iris_with_missing$Sepal.Length)

```

Since I want to apply this function to each column in the dataset, I will apply it across the dataset using the map function:  
```{r replacing missing in iris_with_missing dataset}
iris_replace_missing <- map(iris_with_missing, replace_missing) %>% data.frame()

```

If I want to change the summary measure that is used to fill in the numeric NA cells, I need to add that as an additional argument in the function:
```{r function with different summary statements}

replace_missing_update <- function(df, summary_stat) {
  
  summary_value <- df %>% summary_stat(., na.rm = TRUE) %>% round(., 1)
  virginica<-c("virginica")
  
  if (is.character(df)) {
    df %>% replace(., is.na(df), virginica)
  } else if (is.numeric(df)) {
    df %>% replace(., is.na(df), summary_value)
  }
}

```

```{r replace missing with mean} 

iris_replace_missing_mean <- map(iris_with_missing, replace_missing_update, mean) %>% data.frame()

iris_replace_missing_median <- map(iris_with_missing, replace_missing_update, median) %>% data.frame()

```


##Problem 2

Loading and tidying data:

```{r loading and tidying airbnb data}
library(janitor)
airbnb_data <- read_csv("../data/nyc_airbnb.csv") %>%
  clean_names() %>%
  mutate(rating = review_scores_location / 2) %>%
  select(boro = neighbourhood_group, neighbourhood, rating, price, room_type,
         latitude, longitude)
```

Nesting data frame within boro:

```{r nesting data frame in boro}
airbnb_data_nest<-nest(airbnb_data, neighbourhood:longitude)

```

Nesting the airbnb_data dataset within boro results in a new dataset with `r nrow(airbnb_data_nest)` observations and `r ncol(airbnb_data_nest)` variables: borough name (boro), and the corresponding list columns (data) that contain all the information about neighborhoods, rating, price, room_type, latitude, and longitude for each borough. 


*Rental Price by Rating*

This is a continuous predictor variable 

```{r fitting model for rental price by rating}
#Rating

   airbnb_data_nest %>%
  mutate(model = map(data, ~lm(price ~ rating, data = .x)), 
         results = map(model, broom::tidy)) %>%
  select(-data, -model) %>%
  unnest() %>% knitr::kable()
  


airbnb_data %>%
  ggplot(aes(x = rating, y = price, group = boro, color = boro)) + 
    geom_point() + 
    geom_smooth(method = "lm", formula = y ~ x) +
  facet_grid(. ~ boro) + 
  labs(
    title = "Plot of rental price by rating") +
   theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

The table of slope and intercept values suggest that for all boroughs except Staten Island, there is a positive relationship between rating and price. However, looking at the plots, it appears that the relationship between rating and rental price is not linear and therefore a linear model is not a great model for this data. 

*Rental Price by Room Type*

This is a categorical variable with three possible options: entire home/apt, private room, or shared room, therefore we need 2 dummy variables (k-1). When we run the linear model, "Entire home/apt" is set as the reference variable. 
```{r fitting model for rental prices}
#Room Type
  airbnb_data_nest %>%
  mutate(model = map(data, ~lm(price ~ room_type, data = .x)), 
         results = map(model, broom::tidy)) %>%
  select(-data, -model) %>%
  unnest() %>% knitr::kable()
  

airbnb_data %>%
  ggplot(aes(x = room_type, y = price, group = boro, color = boro)) + 
    geom_point() + 
    geom_smooth(method = "lm", formula = y ~ x) +
  facet_grid(. ~ boro) + labs(
    title = "Plot of rental price by room_type") +
   theme(axis.text.x = element_text(angle = 90, hjust = 1))
```


The table of slope and intercept values show that for all 5 boroughs, there is a negative relationship between price and room type when room_type "Entire house/apartment" is the reference value. However, again when lookingt at the plots, it appears that the relationship between room type and rental price is not linear and therefore a linear model is not a great model for this data. 


##Problem 3


```{r creating function to simulate regression model}
sim_regression <- function(n = 30, beta0 = 1, beta1 =1, beta2, var) {
  sim_data <- tibble(
    xi1 = rnorm(n, 0, 1),
    xi2 = rnorm(n, 0,1),
    y= beta0 +beta1*xi1 + beta2*xi2 + rnorm(n, 0, var)
  )
  ls_fit = lm(y ~ xi1 + xi2, data = sim_data)

  tibble(
  beta2_real = beta2,
  beta2_hat = summary(ls_fit)$coefficients[3,1], 
  pvalue = summary(ls_fit)$coefficients[3,4]
  
  )  
}

beta2_0 <- rerun(5,sim_regression(n=30, beta0=1, beta1=1, beta2 = 0, var = 50)) %>% bind_rows()

```

Repeat the above for β2={1,2,3,4,5,6}--since we're going to be repeating this multiple times, we should make a new function and use a map function to apply it across multiple options for beta2

```{r}

simulate_beta2<- function(n_rep, beta2) {
  rerun(n_rep, sim_regression(n=30, beta0=1, beta1=1, beta2, var = 50)) %>% bind_rows()
}

beta2_options<-c(0:6)

beta2_estimates <- map_df(beta2_options, simulate_beta2, n_rep = 10000)

```


Making a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of β2
 on the x axis: 
 
```{r}

beta2_estimates %>% group_by(beta2_real) %>%
  mutate(n_tests = n()) %>%
 filter(pvalue < 0.05) %>%
  group_by(beta2_real) %>%
  mutate(reject = n(), power = reject/n_tests*100) %>% 
  select(beta2_real, power) %>% 
  unique() %>%
  ggplot(aes(x = beta2_real, y = power)) + 
  geom_bar(stat = "identity") + labs(
    title = "Plot of the power of the test versus the true beta2 value"
  )


```


This plot shows that as effect size increases, the power increases. 



 
Making a plot showing the average estimate of β̂2 on the y axis and the true value of β2 on the x axis:
```{r}
 
beta2_hat <- beta2_estimates %>% group_by(beta2_real) %>%
  mutate(mean_beta2 = mean(beta2_hat), variable = "mean_beta2_hat") %>%
  select(beta2_real, mean_beta2, variable) %>%
  unique() 
  
beta2_reject <- beta2_estimates %>% filter(pvalue < 0.05) %>% 
  group_by(beta2_real) %>%
  mutate(mean_beta2 = mean(beta2_hat), variable = "mean_beta2_reject") %>%
  select(beta2_real, mean_beta2, variable) %>%
  unique() 
 
beta2_summary <- rbind(beta2_hat, beta2_reject) 

beta2_summary %>% 
  ggplot(aes(x = beta2_real, y = mean_beta2, col = variable)) + 
  geom_point() + labs(
    title = "Plot of the true value of beta2 versus the mean estimated beta2 value"
  )
```



As this plot shows, the sample averages of beta2_hat across tests for which the null is rejected are not approximately equal to the true value of β2. This makes sense--in order for the null hypothesis that β2= beta2_real to be rejected, we would expect that the estimated β2 is far from the true β2 value.  



##Problem 4

What I want to do is apply the bootstrap to the simulated dataset `sim_df_const` to obtain theta_hat--to do this, I need to create a function to generate `sim_df_const` with different sample sizes, then apply the bootstrap to the results of this simulation, and then calculate a linear model and extract the parameter estimates: 

```{r Problem 4 function}

library(modelr)

sim_df_const_function <- function(n_samp){
  set.seed(1)
  tibble(
  x = rnorm(n_samp, 1, 1),
  error = rnorm(n_samp, 0, 1),
  y = 2 + 3 * x + error
)
}

sim_df_const_function(25) %>%
  bootstrap(n = 5000) %>% 
  mutate(models = map(strap, ~lm(y ~ x, data = .x)), 
         results = map(models, broom::tidy)) %>%
  select(results) %>% 
  unnest() %>%
  select(term, estimate) %>%
  group_by(term) %>%
  mutate(test_id = c(1:n())) %>%
  spread(term, estimate) %>%
  rename(beta0_hat = '(Intercept)', beta1_hat = 'x') %>%
  mutate(theta_hat = log(beta0_hat/beta1_hat)) %>%
  ggplot(aes(x = theta_hat)) +
  geom_histogram() + labs(
    title = "Distribution of theta_hat when n_sample = 25, bootstrap 5000 times"
  )


```

Since I want to repeat this procedure more than 2 times, changing n_samp each time, I need to put this process into another function:

```{r making this into a function}

sim_df <- function(n_samp, n) {
  sim_df_const_function(n_samp) %>%
  bootstrap(n) %>% 
  mutate(models = map(strap, ~lm(y ~ x, data = .x)), 
         results = map(models, broom::tidy)) %>%
  select(results) %>% 
  unnest() %>%
  select(term, estimate) %>%
  group_by(term) %>%
  mutate(test_id = c(1:n())) %>%
  spread(term, estimate) %>%
  rename(beta0_hat = '(Intercept)', beta1_hat = 'x') %>%
  mutate(theta_hat = log(beta0_hat/beta1_hat)) %>%
  ggplot(aes(x = theta_hat)) +
  geom_histogram() 
}

```

Sample size of the simulated dataset is 50:
```{r Problem 4 n_sample is 50 }

sim_df(n_samp=50, n=5000) + labs(title = "Distribution of theta_hat when n_samp = 50 and n=5000")

```

Sample size of the simulated dataset is 250:
```{r Problem 4 n_sample is 250}

sim_df(n_samp=250, n=5000) + labs(title = "Distribution of theta_hat when n_samp = 250 and n=5000")


```


As we can see from these plots, as n_sample, sample size of the simulated dataset increases, the distributions of theta_hat become less skewed (the tails on both sides are more even), and the distributions shift to the left (more negative), which means that beta0_hats are smaller than beta1_hats, since it is on the log scale. 

